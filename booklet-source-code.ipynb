{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Feature Stores with Feast\n",
    "## The easy-reading booklet to master the key concepts of feature stores and learn how to use Feast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this according to your local configuration\n",
    "COMPUTE_LOCAL_WORKING_FOLDER = 'work/fullstackml/experiments/feast-credit-scoring'\n",
    "\n",
    "from feast import (\n",
    "    FeatureStore, \n",
    "    Entity, \n",
    "    Field, \n",
    "    FeatureService, \n",
    "    FeatureView, \n",
    "    FileSource, \n",
    "    RepoConfig,\n",
    "    types,\n",
    "    ValueType,\n",
    "    PushSource\n",
    "    )\n",
    "\n",
    "from feast.infra.online_stores.sqlite import SqliteOnlineStoreConfig\n",
    "from feast.infra.offline_stores.file import FileOfflineStoreConfig\n",
    "from feast.infra.offline_stores.file_source import SavedDatasetFileStorage\n",
    "from feast.repo_config import RegistryConfig\n",
    "from feast.data_source import PushMode\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup registry, repository, initialize feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_config = RepoConfig(\n",
    "    project=\"credit_scoring\",\n",
    "    registry=RegistryConfig(\n",
    "        registry_type='sqlite',\n",
    "        path=os.path.join(COMPUTE_LOCAL_WORKING_FOLDER,  \n",
    "        'fs',\n",
    "        'registry.db')),\n",
    "    provider=\"local\",\n",
    "    entity_key_serialization_version=2,\n",
    "    online_store=SqliteOnlineStoreConfig(\n",
    "        type='sqlite', \n",
    "        path=os.path.join(COMPUTE_LOCAL_WORKING_FOLDER, \n",
    "        'fs',\n",
    "        'online_store.db')),\n",
    "    offline_store=FileOfflineStoreConfig(type='file')\n",
    "    )\n",
    "        \n",
    "\n",
    "fs = FeatureStore(config=repo_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define entities, festure views and register them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/feast/lib/python3.10/site-packages/feast/infra/offline_stores/file_source.py:161: FutureWarning: 'ParquetDataset.schema' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.schema' attribute instead (which will return an Arrow schema instead of a Parquet schema).\n",
      "  schema = ParquetDataset(path).schema.to_arrow_schema()\n"
     ]
    }
   ],
   "source": [
    "zipcode = Entity(\n",
    "    name=\"zipcode\", \n",
    "    join_keys=[\"zipcode\"]\n",
    "    )\n",
    "dob_ssn = Entity(\n",
    "    name=\"dob_ssn\",\n",
    "    value_type=ValueType.STRING,\n",
    "    join_keys=[\"dob_ssn\"],\n",
    "    description=\"Date of birth and last four digits of social security number\"\n",
    "    )\n",
    "\n",
    "zipcode_features = FeatureView(\n",
    "    name=\"zipcode_features\",\n",
    "    entities=[zipcode],\n",
    "    ttl=timedelta(days=3650),\n",
    "    schema=[\n",
    "        Field(name=\"city\", dtype=types.String),\n",
    "        Field(name=\"state\", dtype=types.String),\n",
    "        Field(name=\"location_type\", dtype=types.String),\n",
    "        Field(name=\"tax_returns_filed\", dtype=types.Int64),\n",
    "        Field(name=\"population\", dtype=types.Int64),\n",
    "        Field(name=\"total_wages\", dtype=types.Int64),\n",
    "    ],\n",
    "    source=FileSource(\n",
    "        path=os.path.join(\n",
    "            COMPUTE_LOCAL_WORKING_FOLDER,\n",
    "            'data',\n",
    "            'zipcode_table.parquet'),\n",
    "        timestamp_field=\"event_timestamp\",\n",
    "        #created_timestamp_column=\"created_timestamp\",\n",
    "    )\n",
    ")\n",
    "\n",
    "credit_history = FeatureView(\n",
    "    name=\"credit_history\",\n",
    "    entities=[dob_ssn],\n",
    "    ttl=timedelta(days=90),\n",
    "    source=FileSource(\n",
    "        path=os.path.join(\n",
    "            COMPUTE_LOCAL_WORKING_FOLDER,\n",
    "            'data',\n",
    "            'credit_history.parquet'),\n",
    "        timestamp_field=\"event_timestamp\",\n",
    "        #created_timestamp_column=\"created_timestamp\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Register entities and feature views\n",
    "fs.apply([\n",
    "    credit_history, \n",
    "    dob_ssn, \n",
    "    zipcode, \n",
    "    zipcode_features]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating timestamps for the data  \n",
    "timestamps = pd.date_range(      \n",
    "    end=pd.Timestamp.now(),      \n",
    "    periods=len(data_df),      \n",
    "    freq='D').to_frame(name=\"event_timestamp\", index=False) \n",
    "\n",
    "# Adding the timestamp column to the DataFrame\n",
    "data_df = pd.concat(objs=[data_df, timestamps], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = pd.read_parquet(os.path.join(\n",
    "   COMPUTE_LOCAL_WORKING_FOLDER,\n",
    "   'data',\n",
    "   'loan_table.parquet'))\n",
    "\n",
    "feast_features = [\n",
    "   \"zipcode_features:city\",\n",
    "   \"zipcode_features:state\",\n",
    "   \"zipcode_features:location_type\",\n",
    "   \"zipcode_features:tax_returns_filed\",\n",
    "   \"zipcode_features:population\",\n",
    "   \"zipcode_features:total_wages\",\n",
    "   \"credit_history:credit_card_due\",\n",
    "   \"credit_history:mortgage_due\",\n",
    "   \"credit_history:student_loan_due\",\n",
    "   \"credit_history:vehicle_loan_due\",\n",
    "   \"credit_history:hard_pulls\",\n",
    "   \"credit_history:missed_payments_2y\",\n",
    "   \"credit_history:missed_payments_1y\",\n",
    "   \"credit_history:missed_payments_6m\",\n",
    "   \"credit_history:bankruptcies\",\n",
    "]\n",
    "\n",
    "training_data = fs.get_historical_features(\n",
    "   entity_df=loan_data, \n",
    "   features=feast_features\n",
    ")\n",
    "\n",
    "training_df = training_data.to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the generated dataset for use in the moderation phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the dataset as a local file\n",
    "dataset = fs.create_saved_dataset(\n",
    "    from_=training_data,\n",
    "    name=\"credit_scoring_dataset\",\n",
    "    storage=SavedDatasetFileStorage(os.path.join(\n",
    "            COMPUTE_LOCAL_WORKING_FOLDER,\n",
    "            'data',\n",
    "            'credit_scoring_dataset.parquet'))\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How retrieve a stored dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/feast/lib/python3.10/site-packages/feast/feature_store.py:1235: RuntimeWarning: Retrieving datasets is an experimental feature. This API is unstable and it could and most probably will be changed in the future. We do not guarantee that future changes will maintain backward compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Retrieving the saved dataset and converting it to a DataFrame\n",
    "training_df = fs.get_saved_dataset(name=\"credit_scoring_dataset\").to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Materialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Materializing \u001b[1m\u001b[32m2\u001b[0m feature views to \u001b[1m\u001b[32m2022-11-13 22:09:20+00:00\u001b[0m into the \u001b[1m\u001b[32msqlite\u001b[0m online store.\n",
      "\n",
      "\u001b[1m\u001b[32mcredit_history\u001b[0m from \u001b[1m\u001b[32m2022-08-15 22:09:20+00:00\u001b[0m to \u001b[1m\u001b[32m2022-11-13 22:09:20+00:00\u001b[0m:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mzipcode_features\u001b[0m from \u001b[1m\u001b[32m2012-11-15 22:09:29+00:00\u001b[0m to \u001b[1m\u001b[32m2022-11-13 22:09:20+00:00\u001b[0m:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 28845/28845 [00:11<00:00, 2602.80it/s]\n"
     ]
    }
   ],
   "source": [
    "fs.materialize_incremental(end_date=datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_loan_request = {\n",
    "   \"zipcode\": [76104],\n",
    "   \"dob_ssn\": [\"19500806_6783\"],\n",
    "   \"person_age\": [133],\n",
    "   \"person_income\": [59000],\n",
    "   \"person_home_ownership\": [\"RENT\"],\n",
    "   \"person_emp_length\": [123.0],\n",
    "   \"loan_intent\": [\"PERSONAL\"],\n",
    "   \"loan_amnt\": [35000],\n",
    "   \"loan_int_rate\": [16.02],\n",
    "}\n",
    "\n",
    "# Next we fetch our online features \n",
    "customer_zipcode = dummy_loan_request['zipcode'][0]\n",
    "dob_ssn = dummy_loan_request[\"dob_ssn\"][0]\n",
    "\n",
    "feature_vector = fs.get_online_features(\n",
    "   entity_rows=[{\"zipcode\": customer_zipcode, \"dob_ssn\": dob_ssn}],\n",
    "   features=feast_features,\n",
    ").to_dict()\n",
    "\n",
    "# Converting the features to a DataFrame\n",
    "features = dummy_loan_request.copy()\n",
    "features.update(feature_vector)\n",
    "features_df = pd.DataFrame.from_dict(data=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature service definition (it consists of references to multiple feature views)\n",
    "mixedviews_fs = FeatureService(\n",
    "    name=\"mixed_views\",\n",
    "    features=[\n",
    "        zipcode_features[[\"city\",\"state\"]],\n",
    "        credit_history[[\"mortgage_due\"]]\n",
    "        ]\n",
    ")\n",
    "\n",
    "fs.apply([mixedviews_fs])\n",
    "\n",
    "# Now a call can be made to this feature service to retrieve required data that may be coming from one or more feature views -\n",
    "features_to_fetch = fs.get_feature_service(\"mixed_views\")\n",
    "\n",
    "entity_rows = [\n",
    "        {\n",
    "            \"zipcode\": 76104,\n",
    "            \"dob_ssn\": '19500806_6783',\n",
    "        },\n",
    "    ]\n",
    "\n",
    "#  Get features value from the online store\n",
    "returned_features = fs.get_online_features(\n",
    "        features=features_to_fetch,\n",
    "        entity_rows=entity_rows\n",
    "    ).to_dict()\n",
    "\n",
    "# or get from offline store\n",
    "returned_features_off = fs.get_historical_features(\n",
    "    features=features_to_fetch, \n",
    "    entity_df=loan_data).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'zipcode': [76104],\n",
       " 'dob_ssn': ['19500806_6783'],\n",
       " 'state': ['TX'],\n",
       " 'city': ['FORT WORTH'],\n",
       " 'mortgage_due': [None]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returned_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/feast/lib/python3.10/site-packages/feast/infra/offline_stores/file_source.py:161: FutureWarning: 'ParquetDataset.schema' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.schema' attribute instead (which will return an Arrow schema instead of a Parquet schema).\n",
      "  schema = ParquetDataset(path).schema.to_arrow_schema()\n"
     ]
    }
   ],
   "source": [
    "zipcode_push_source = PushSource(\n",
    "    name=\"zipcode_push_source\",\n",
    "    batch_source=FileSource(\n",
    "        path=os.path.join(\n",
    "            COMPUTE_LOCAL_WORKING_FOLDER,\n",
    "            'data',\n",
    "            'zipcode_table.parquet'),\n",
    "        timestamp_field=\"event_timestamp\",\n",
    "    )\n",
    ")\n",
    "\n",
    "zipcode_features_push = FeatureView(\n",
    "    name=\"zipcode_features_push\",\n",
    "    entities=[zipcode],\n",
    "    ttl=timedelta(days=3650),\n",
    "    source=zipcode_push_source\n",
    ")\n",
    "\n",
    "fs.apply([zipcode_features_push])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/feast/lib/python3.10/site-packages/feast/infra/offline_stores/file_source.py:161: FutureWarning: 'ParquetDataset.schema' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.schema' attribute instead (which will return an Arrow schema instead of a Parquet schema).\n",
      "  schema = ParquetDataset(path).schema.to_arrow_schema()\n",
      "/opt/conda/envs/feast/lib/python3.10/site-packages/feast/infra/offline_stores/file_source.py:161: FutureWarning: 'ParquetDataset.schema' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.schema' attribute instead (which will return an Arrow schema instead of a Parquet schema).\n",
      "  schema = ParquetDataset(path).schema.to_arrow_schema()\n"
     ]
    }
   ],
   "source": [
    "# new dummy data to push\n",
    "pushed_data = [{'zipcode': 1111,\n",
    " 'city': 'NEW ROME',\n",
    " 'state': 'NJ',\n",
    " 'location_type': 'PRIMARY',\n",
    " 'tax_returns_filed': 13245,\n",
    " 'population': 24083,\n",
    " 'total_wages': 1089095041,\n",
    " 'event_timestamp': pd.Timestamp('2017-01-01 12:00:00+0000', tz='UTC')}]\n",
    "\n",
    "# execute the push\n",
    "fs.push(\"zipcode_push_source\", pd.DataFrame.from_dict(data=pushed_data), to=PushMode.ONLINE_AND_OFFLINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'zipcode': [1111],\n",
       " 'state': ['NJ'],\n",
       " 'total_wages': [1089095041],\n",
       " 'population': [24083],\n",
       " 'city': ['NEW ROME'],\n",
       " 'tax_returns_filed': [13245],\n",
       " 'location_type': ['PRIMARY']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get just pushed data\n",
    "\n",
    "fs.get_online_features(\n",
    "   entity_rows=[{\"zipcode\": 1111}],\n",
    "   features=[\n",
    "   \"zipcode_features_push:city\",\n",
    "   \"zipcode_features_push:state\",\n",
    "   \"zipcode_features_push:location_type\",\n",
    "   \"zipcode_features_push:tax_returns_filed\",\n",
    "   \"zipcode_features_push:population\",\n",
    "   \"zipcode_features_push:total_wages\"],\n",
    ").to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the feature transformation server locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a python file in the project folder and copy the following instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPUTE_LOCAL_WORKING_FOLDER = 'work/fullstackml/experiments/feast-credit-scoring'\n",
    "\n",
    "from feast import FeatureStore, RepoConfig\n",
    "from feast.infra.online_stores.sqlite import SqliteOnlineStoreConfig\n",
    "from feast.infra.offline_stores.file import FileOfflineStoreConfig\n",
    "from feast.repo_config import RegistryConfig\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "repo_config = RepoConfig(\n",
    "    project=\"credit_scoring\",\n",
    "    registry=RegistryConfig(\n",
    "        registry_type='sqlite',\n",
    "        path=os.path.join(COMPUTE_LOCAL_WORKING_FOLDER,\n",
    "        'fs',\n",
    "        'registry.db')),\n",
    "    provider=\"local\",\n",
    "    entity_key_serialization_version=2,\n",
    "    online_store=SqliteOnlineStoreConfig(\n",
    "        type='sqlite',\n",
    "        path=os.path.join(COMPUTE_LOCAL_WORKING_FOLDER,\n",
    "        'fs',\n",
    "        'online_store.db')),\n",
    "    offline_store=FileOfflineStoreConfig(type='file')\n",
    "    )\n",
    "\n",
    "fs = FeatureStore(config=repo_config)\n",
    "\n",
    "# if you're working from inside a container set host to 0.0.0.0 and export port 8889 on host machine\n",
    "fs.serve(host='127.0.0.1',port=8889,type_='http',no_access_log=False,no_feature_log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "curl -X POST \\\n",
    "  \"http://localhost:8889/get-online-features\" \\\n",
    "  -d '{\n",
    "    \"entities\": {\n",
    "        \"zipcode\": [\n",
    "            1111\n",
    "        ]\n",
    "    },\n",
    "    \"features\": [\n",
    "        \"zipcode_features_push:city\",\n",
    "        \"zipcode_features_push:state\",\n",
    "        \"zipcode_features_push:location_type\",\n",
    "        \"zipcode_features_push:tax_returns_filed\",\n",
    "        \"zipcode_features_push:population\",\n",
    "        \"zipcode_features_push:total_wages\"\n",
    "    ]\n",
    "}' | jq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the UI server locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a python file in the project folder and copy the following instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPUTE_LOCAL_WORKING_FOLDER = 'work/fullstackml/experiments/feast-credit-scoring'\n",
    "\n",
    "from feast import FeatureStore, RepoConfig\n",
    "from feast.infra.online_stores.sqlite import SqliteOnlineStoreConfig\n",
    "from feast.infra.offline_stores.file import FileOfflineStoreConfig\n",
    "from feast.repo_config import RegistryConfig\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "repo_config = RepoConfig(\n",
    "    project=\"credit_scoring\",\n",
    "    registry=RegistryConfig(\n",
    "        registry_type='sqlite',\n",
    "        path=os.path.join(COMPUTE_LOCAL_WORKING_FOLDER,\n",
    "        'fs',\n",
    "        'registry.db')),\n",
    "    provider=\"local\",\n",
    "    entity_key_serialization_version=2,\n",
    "    online_store=SqliteOnlineStoreConfig(\n",
    "        type='sqlite',\n",
    "        path=os.path.join(COMPUTE_LOCAL_WORKING_FOLDER,\n",
    "        'fs',\n",
    "        'online_store.db')),\n",
    "    offline_store=FileOfflineStoreConfig(type='file')\n",
    "    )\n",
    "\n",
    "fs = FeatureStore(config=repo_config)\n",
    "\n",
    "# if you're working from inside a container set host to 0.0.0.0 and export port 8889 on host machine\n",
    "fs.serve_ui(host='127.0.0.1',port=8889, get_registry_dump=Callable,registry_ttl_sec=5)\n",
    "# registry_ttl_sec is number of seconds after which the registry is refreshed (default 5)\n",
    "# open your browser on http://127.0.0.1:8889"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erase all configurations, registry, and files generated at the time of the feature repo initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.teardown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feast",
   "language": "python",
   "name": "feast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
